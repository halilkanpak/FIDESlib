% !TEX program = pdflatex
\documentclass[10pt,twocolumn]{article}

% -------------------- Dense page setup --------------------
\usepackage[letterpaper,margin=0.62in,includeheadfoot]{geometry}
\setlength{\columnsep}{0.18in}
\setlength{\parindent}{0pt}
\setlength{\parskip}{2.2pt}
\linespread{0.965}

\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{microtype}
\usepackage{amsmath,amssymb}
\usepackage{enumitem}
\setlist{leftmargin=*,itemsep=1.0pt,topsep=2.0pt,parsep=0pt,partopsep=0pt}
\usepackage{titlesec}
\titlespacing*{\section}{0pt}{4pt}{2pt}
\titlespacing*{\subsection}{0pt}{3pt}{1.5pt}
\titlespacing*{\subsubsection}{0pt}{2pt}{1pt}

\usepackage{booktabs}
\usepackage[colorlinks=true,linkcolor=blue,citecolor=blue,urlcolor=blue]{hyperref}
\usepackage[nameinlink,noabbrev]{cleveref}

\usepackage{tikz}
\usetikzlibrary{shapes,arrows,positioning,fit,calc}

\begin{document}

\begin{center}
{\Large \textbf{Multi-GPU Acceleration of FHE Kernels}}\\
\vspace{2pt}
{\normalsize Final Implementation Report}\\
\vspace{2pt}
{\small Halil \.{I}brahim Kanpak \quad|\quad \href{https://github.com/hkanpak21/FIDESlib}{FIDESlib (fork with Multi-GPU support)}}
\end{center}

\vspace{-4pt}

% ==========================================================
\section{Problem Statement and Motivation}
Fully Homomorphic Encryption (FHE) enables computation directly on encrypted data, but practical deployment is constrained by a small set of extremely expensive primitives. In CKKS (approximate arithmetic), \emph{homomorphic matrix multiplication} (MatMul) and \emph{bootstrapping} often dominate runtime because they repeatedly invoke polynomial transforms (NTT/INTT), key switching, rotations (Galois automorphisms), and modulus/base conversion. Single-GPU acceleration is now feasible, but efficient \emph{multi-GPU} scaling was limited by shared static state in existing libraries. In this project, I extended the FIDESlib library to support multi-GPU parallelism, resolving core architectural bottlenecks that prevented independent GPU operations.


\section{Literature Review}
GPU-focused CKKS work concentrates on accelerating the dominant building blocks---NTT/INTT, pointwise RNS arithmetic, and key switching/rotations---because these are the core cost drivers for both MatMul and bootstrapping. FIDESlib positions itself as an open-source, feature-complete CKKS GPU stack (including bootstrapping) with benchmarking and interoperability with OpenFHE for correctness validation.\cite{fides-paper,fides-github} Common parallelism opportunities are well known: (i) \emph{task/data parallelism} across independent ciphertexts or MatMul tiles, and (ii) \emph{RNS/modulus sharding} across prime limbs where many kernels are limb-separable. In practice, multi-GPU performance depends on communication and synchronization placement; therefore, I will implement communication-aware scheduling and profile end-to-end execution to quantify what scales and what becomes communication-limited.

% ==========================================================
\section{Baseline and Reference Results}
\textbf{Baseline:} FIDESlib (MIT), a CUDA-based CKKS library.\cite{fides-paper,fides-github}
Published single-GPU results on RTX 4090 serve as a reference. My implementation targets scaling efficiency on modern L4 GPUs.

\begin{table}[h]
\centering
\footnotesize
\begin{tabular}{lrr}
\toprule
\textbf{Operation (RTX 4090)} & \textbf{Time} & \textbf{Ref.} \\
\midrule
ScalarMult & 44.15 $\mu$s & Table V \\
HRotate    & 1.107 ms     & Table V \\
HMult      & 1.084 ms     & Table V \\
Bootstrap (Slots=16k) & 112 ms  & Table VI \\
\bottomrule
\end{tabular}
\caption{Published single-GPU reference results.}
\end{table}



% ==========================================================
\section{Actual Implementation and Technical Challenges}
The transformation from a single-GPU library to a multi-GPU one required systemic changes to FIDESlib's handling of GPU resources and cryptographic state.

\subsection{Per-Context Key Management}
The primary blocker for multi-GPU support was FIDESlib's use of \textbf{static global variables} for evaluation keys, rotation keys, and bootstrap precomputations. In a multi-GPU environment, launching multiple kernels on different GPUs caused these global variables to be overwritten, leading to incorrect results or invalid memory accesses.
\textbf{Solution:} I re-engineered the \texttt{Context} class to store keys as instance-level member variables, ensuring that each GPU context maintains its own independent set of cryptographic parameters.

\subsection{Device-Aware CUDA Graph Caching}
FIDESlib uses CUDA graphs to minimize kernel launch overhead for NTT/INTT. Originally, the graph cache was keyed only by the transform size. Since CUDA graphs are bound to the device they were captured on, this caused crashes when multiple GPUs shared the same cache.
\textbf{Solution:} I modified the cache indexing to use a \texttt{std::pair<int, int>} containing both the transform size and the \texttt{device\_id}.

\subsection{Constant Memory Initialization}
I discovered that NTT constants (\texttt{psi} tables) were only being copied to GPU 0. I implemented an initialization tracking system in \texttt{ConstantsGPU.cu} to ensure that all participating GPUs are properly configured during the multi-context setup.

% ==========================================================
\section{Communication Layer: NCCL Adoption}
Although NVSHMEM was initially proposed, its deployment on the school cluster (and cloud platforms like RunPod) proved difficult due to dependency mismatches. I implemented \textbf{NCCL} (NVIDIA Collective Communications Library) for its robust support of \texttt{all-reduce} operations, which are essential for aggregating partial products in parallel MatMul. NCCL provided better stability and easier integration with FIDESlib's stream-based execution.

% ==========================================================
\section{Experiment Environment and Results}
\textbf{Compute Environment:} Operations were conducted on \textbf{RunPod} using 2x NVIDIA L4 GPUs (Ada Lovelace, 24GB VRAM). The interconnect is PCIe-based.

\subsection{Performance Scaling}
I evaluated a MatMul-style workload (8192 $\times$ 128) across 1 and 2 GPUs.
\begin{itemize}[noitemsep]
    \item \textbf{Single GPU Latency:} 118.21 ms
    \item \textbf{Dual GPU Latency:} 47.14 ms
    \item \textbf{Observed Speedup:} \textbf{2.51$\times$}
\end{itemize}
The super-linear scaling indicates that reducing the workload size per GPU significantly improves L2 cache residency and reduces memory bandwidth contention.

% ==========================================================
\section{Computation Graph for HE MatMul}
The logical flow of the implemented parallel MatMul is as follows:

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{figures/ComputationGraphHEMatMul.png}
    \caption{Computation graph of HE MatMul operation}
    \label{fig:HEMatMul}
\end{figure}


% ==========================================================
\section{Conclusion}
This project successfully transformed FIDESlib into a multi-GPU capable library. By resolving static state conflicts and ensuring device-specific cache isolation, we achieved scalable HE performance on modern GPU hardware.

% ==========================================================
{\footnotesize
\begin{thebibliography}{9}\setlength{\itemsep}{1pt}
\bibitem{fides-paper}
C.~Agull{\'o}-Domingo et al., ``FIDESlib: A Fully-Fledged Open-Source FHE Library for Efficient CKKS on GPUs,'' arXiv:2507.04775 (2025).
\bibitem{fides-github}
\href{https://github.com/CAPS-UMU/FIDESlib}{https://github.com/CAPS-UMU/FIDESlib}
\end{thebibliography}
}

\end{document}


